{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8066917,"sourceType":"datasetVersion","datasetId":4759383}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport torch\nfrom datasets import Dataset\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\nfrom transformers import Trainer, TrainingArguments\n\n# Load pre-trained GPT-2 model and tokenizer\nmodel_name = \"gpt2\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:18:42.621083Z","iopub.execute_input":"2024-04-19T16:18:42.621433Z","iopub.status.idle":"2024-04-19T16:19:06.930371Z","shell.execute_reply.started":"2024-04-19T16:18:42.621397Z","shell.execute_reply":"2024-04-19T16:19:06.929459Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-19 16:18:53.540785: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-19 16:18:53.540914: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-19 16:18:53.670481: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d1fad8272a45faa726384f0495211c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e152b3b51de4ea99b7297b86817e02b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef2b995bb8054e16a96450b51bafd7c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1904a6a2a574d759edc402d3d6a2d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9205ca3c2a4c4fa6ac00c6ced76aa196"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d52f1eb27c42499ea9488c7bf45c60d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8ccf1e640d4b668ffc2ea21e7a5a15"}},"metadata":{}}]},{"cell_type":"code","source":"# Load prompt and response data from JSON file\nfrom sklearn.model_selection import train_test_split\n\nfile_path = \"/kaggle/input/commands/dataset.json\"\nwith open(file_path, \"r\", encoding=\"utf-8\") as file:\n    data = json.load(file)\n\n\n# Extract prompts and commands\nprompts = [item['prompt'] for item in data]\ncommands = [item['command'] for item in data]\n\n# Create a dictionary\ndata_dict = {\n    'prompt': prompts,\n    'command': commands\n}\n\n# train, test = train_test_split(data,test_size=0.15)\n# print(train)\n\n# train_dataset = Dataset.from_dict(train)\n# test_dataset = Dataset.from_dict(test)\n# print(train_dataset)\n\n# Create Dataset object\ndataset = Dataset.from_dict(data_dict)\nprint(dataset[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:20:12.440971Z","iopub.execute_input":"2024-04-19T16:20:12.441996Z","iopub.status.idle":"2024-04-19T16:20:12.498013Z","shell.execute_reply.started":"2024-04-19T16:20:12.441965Z","shell.execute_reply":"2024-04-19T16:20:12.497148Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"{'prompt': 'List files and directories in the current directory', 'command': 'ls'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize the dataset\ndef tokenize_function(example):\n    return tokenizer(example[\"prompt\"], example[\"command\"], padding=True, truncation=True)\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:20:49.548708Z","iopub.execute_input":"2024-04-19T16:20:49.549393Z","iopub.status.idle":"2024-04-19T16:20:51.871589Z","shell.execute_reply.started":"2024-04-19T16:20:49.549362Z","shell.execute_reply":"2024-04-19T16:20:51.870671Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/179 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63ed14a67c445cc98afd631d6aa5efc"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'command', 'input_ids', 'attention_mask'],\n    num_rows: 179\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Define data collator\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:20:55.800369Z","iopub.execute_input":"2024-04-19T16:20:55.800707Z","iopub.status.idle":"2024-04-19T16:20:55.805092Z","shell.execute_reply.started":"2024-04-19T16:20:55.800684Z","shell.execute_reply":"2024-04-19T16:20:55.803982Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Fine-tuning arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./finetuned_gpt2\",\n    overwrite_output_dir=True,\n    num_train_epochs=5,\n    per_device_train_batch_size=4,\n    save_steps=800,\n    save_total_limit=2,\n)\n\n# Define trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=tokenized_dataset,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:20:58.575339Z","iopub.execute_input":"2024-04-19T16:20:58.575699Z","iopub.status.idle":"2024-04-19T16:20:59.711922Z","shell.execute_reply.started":"2024-04-19T16:20:58.575674Z","shell.execute_reply":"2024-04-19T16:20:59.711166Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fine-tune the model\ntrainer.train()\n\n# Save the fine-tuned model\ntrainer.save_model(\"./finetuned_gpt2\")\n\n\n# Save the tokenizer\ntokenizer.save_pretrained(\"./finetuned_gpt2\")","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:21:05.728107Z","iopub.execute_input":"2024-04-19T16:21:05.728458Z","iopub.status.idle":"2024-04-19T16:24:54.173233Z","shell.execute_reply.started":"2024-04-19T16:21:05.728432Z","shell.execute_reply":"2024-04-19T16:24:54.171809Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240419_162421-t0v0pgq7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kurkure/huggingface/runs/t0v0pgq7/workspace' target=\"_blank\">stellar-breeze-10</a></strong> to <a href='https://wandb.ai/kurkure/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kurkure/huggingface' target=\"_blank\">https://wandb.ai/kurkure/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kurkure/huggingface/runs/t0v0pgq7/workspace' target=\"_blank\">https://wandb.ai/kurkure/huggingface/runs/t0v0pgq7/workspace</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='225' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [225/225 00:13, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('./finetuned_gpt2/tokenizer_config.json',\n './finetuned_gpt2/special_tokens_map.json',\n './finetuned_gpt2/vocab.json',\n './finetuned_gpt2/merges.txt',\n './finetuned_gpt2/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\n# Load fine-tuned GPT-2 model and tokenizer\nmodel_name = \"./finetuned_gpt2\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:24:58.578383Z","iopub.execute_input":"2024-04-19T16:24:58.578979Z","iopub.status.idle":"2024-04-19T16:24:58.873963Z","shell.execute_reply.started":"2024-04-19T16:24:58.578948Z","shell.execute_reply":"2024-04-19T16:24:58.872898Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define the prompt\nprompt = \"create a directory named 'test'\"\n\n# Tokenize the prompt\ninput_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n\n# Generate response\noutput = model.generate(input_ids, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:25:03.488938Z","iopub.execute_input":"2024-04-19T16:25:03.490028Z","iopub.status.idle":"2024-04-19T16:25:05.076190Z","shell.execute_reply.started":"2024-04-19T16:25:03.489987Z","shell.execute_reply":"2024-04-19T16:25:05.075088Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(output[0])","metadata":{"execution":{"iopub.status.busy":"2024-04-09T06:34:11.074482Z","iopub.execute_input":"2024-04-09T06:34:11.075213Z","iopub.status.idle":"2024-04-09T06:34:11.083648Z","shell.execute_reply.started":"2024-04-09T06:34:11.075183Z","shell.execute_reply":"2024-04-09T06:34:11.082535Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"tensor([27914,   262,  2393,  3706,   705, 20688,    13, 14116,     6, 26224,\n         1672,    13, 14116,  1672,    13, 14116,   930,   266,    66,   532,\n           75,  1672,    13, 14116,   930,  7894,   532,    77,   352,   930,\n         7894,   532,    77,   352,   930,   266,    66,   532,    75,  1672,\n           13, 14116,   930,  7894,   532,    77,   352,   930,  7894,   532])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Decode the generated response\n\n\nresponse = tokenizer.decode(output[0], skip_special_tokens=True)\n\n# # Print the response\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T16:25:11.663373Z","iopub.execute_input":"2024-04-19T16:25:11.664030Z","iopub.status.idle":"2024-04-19T16:25:11.673498Z","shell.execute_reply.started":"2024-04-19T16:25:11.664002Z","shell.execute_reply":"2024-04-19T16:25:11.671800Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"create a directory named 'test'mkdir test_directory test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_\n","output_type":"stream"}]}]}